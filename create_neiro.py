# –ø—Ä–æ–≥—Ä–∞–º–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∏ –µ—ë –æ–±—É—á–µ–Ω–∏—è

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import os

# –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å
if os.path.exists('dataset_1.npz'):
    print("üéØ –ó–∞–≥—Ä—É–∂–∞–µ–º –ö–ê–°–¢–û–ú–ù–´–ô –¥–∞—Ç–∞—Å–µ—Ç...")
    custom_data = np.load('dataset_1.npz')
    x_train = custom_data['images']
    y_train = custom_data['labels']
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ
    split_idx = int(0.8 * len(x_train))
    x_train, x_test = x_train[:split_idx], x_train[split_idx:]
    y_train, y_test = y_train[:split_idx], y_train[split_idx:]
    
    print(f"–ö–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(x_train)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö, {len(x_test)} —Ç–µ—Å—Ç–æ–≤—ã—Ö")
    
else:
    # –∑–∞–≥—Ä—É–∂–∞–µ–º MNIST –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    print("üìö –ó–∞–≥—Ä—É–∂–∞–µ–º MNIST...")
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    x_train = x_train.astype("float32") / 255.0
    x_test = x_test.astype("float32") / 255.0

# –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏–µ –¥–ª—è –∫–∞–Ω–∞–ª–∞
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

print(f"–§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {x_train.shape}")

# –ü–†–û–°–¢–ê–Ø –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
model = keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'), 
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(10, activation='softmax')  # softmax –≤–º–µ—Å—Ç–æ logits
])
# –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å 
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# –û–±—É—á–∞–µ–º
print("–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å...")
history = model.fit(x_train, y_train,
                    epochs=15,
                    batch_size=32,
                    validation_data=(x_test, y_test))

model.save('–æ–≤–æ—â.h5')
print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")

test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {test_acc:.4f}")